# -*- coding: utf-8 -*-
"""NN from Scratch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18n8J1T20Vg7s0QgzNQB1gRhfBxymefHB
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix, classification_report

# load the dataset
url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'
names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']
dataset = pd.read_csv(url, names=names)

# split into input (X) and output (y) variables
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 4].values

# feature scaling
sc = StandardScaler()
X = sc.fit_transform(X)

# train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# initialize the classifier
classifier = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)

# train the classifier
classifier.fit(X_train, y_train)

# make predictions on unseen data
y_pred = classifier.predict(X_test)

# evaluate the classifier
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

import numpy as np
from tensorflow.keras.datasets import mnist
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

# Load MNIST dataset
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Preprocess data
train_images = train_images.reshape((-1, 28 * 28)) / 255.0
test_images = test_images.reshape((-1, 28 * 28)) / 255.0

train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# Neural network architecture
class NeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size):
        self.weights1 = np.random.randn(input_size, hidden_size)
        self.bias1 = np.zeros((1, hidden_size))
        self.weights2 = np.random.randn(hidden_size, output_size)
        self.bias2 = np.zeros((1, output_size))

    def forward(self, inputs):
        self.layer1 = np.dot(inputs, self.weights1) + self.bias1
        self.activation1 = self.sigmoid(self.layer1)
        self.layer2 = np.dot(self.activation1, self.weights2) + self.bias2
        self.activation2 = self.softmax(self.layer2)
        return self.activation2

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def softmax(self, x):
        exp_values = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_values / np.sum(exp_values, axis=1, keepdims=True)

    def backward(self, inputs, outputs, learning_rate):
        batch_size = inputs.shape[0]

        output_error = self.activation2 - outputs
        weight2_gradients = np.dot(self.activation1.T, output_error) / batch_size
        bias2_gradients = np.sum(output_error, axis=0, keepdims=True) / batch_size

        hidden_error = np.dot(output_error, self.weights2.T) * (self.activation1 * (1 - self.activation1))
        weight1_gradients = np.dot(inputs.T, hidden_error) / batch_size
        bias1_gradients = np.sum(hidden_error, axis=0, keepdims=True) / batch_size

        self.weights2 -= learning_rate * weight2_gradients
        self.bias2 -= learning_rate * bias2_gradients
        self.weights1 -= learning_rate * weight1_gradients
        self.bias1 -= learning_rate * bias1_gradients

    def train(self, inputs, outputs, learning_rate, epochs):
        for epoch in range(epochs):
            predictions = self.forward(inputs)
            self.backward(inputs, outputs, learning_rate)
            if epoch % 10 == 0:
                loss = -np.sum(outputs * np.log(predictions + 1e-10)) / len(outputs)
                print(f"Epoch {epoch}, Loss: {loss}")

# Set up and train the neural network
input_size = 784
hidden_size = 128
output_size = 10

model = NeuralNetwork(input_size, hidden_size, output_size)
learning_rate = 0.1
epochs = 1000

model.train(train_images, train_labels, learning_rate, epochs)

# Test the trained model
def test(model, test_inputs, test_outputs):
    predictions = model.forward(test_inputs)
    accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(test_outputs, axis=1))
    print(f"Test Accuracy: {accuracy * 100}%")

test(model, test_images, test_labels)